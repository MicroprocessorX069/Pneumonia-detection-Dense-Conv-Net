# -*- coding: utf-8 -*-
"""train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aSdnrVFLC_qgNPfjhVmZTYWYU6wjEFGc
"""



# from google.colab import drive
# drive.mount('/content/drive/')

#import libraries
import torch 
import torchvision
import torch.nn as nn
import numpy as np
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.nn import functional as F
from torch import topk
from matplotlib.pyplot import imshow
import os
from PIL import Image
from torchvision import models, transforms
from torch.autograd import Variable
import skimage.transform
from data_loader import loadTrainData
from model import DenseNet121
from extras import SaveFeatures, getCAM

#device supporting the training
device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# the two classes here are pneumonia and non pneumonia
# Hyper parameters.
num_classes=2
num_epochs=1000
batch_size=64
learning_rate=0.001

data_dir="/content/drive/My Drive/Projects/Pneumonia detection/chest_xray/chest_xray/"
train_loader, val_loader,test_loader=loadTrainData(data_dir)
model=DenseNet121(num_classes).to(device) # pretrained model can be loaded too. Just add pretrained =True
criterion=nn.CrossEntropyLoss() 
optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)

"""##Model"""



#Training process
total_step=len(train_loader)
for epoch in range(num_epochs):
  for i,(images,labels) in enumerate(train_loader):
    # batch pair of image and label using data loader
    images=images.to(device) 
    labels=labels.to(device)
    
    #Getting output from network model
    outputs=model(images)
    # calculating cross entropy loss between predicted label and real label
    loss=criterion(outputs,labels)
    #print(images.size())
    # batch_size, channels, height width of the image batch
    bs, c, h, w = images.size() #batch_size
    input_var = torch.autograd.Variable(images.view(-1, c, h, w).cuda(), volatile=True)
    # For validation
    output = model(input_var)
    output_mean = output.view(bs, -1).mean(1) #calculating the mean output of the batch
    #training 
    optimizer.zero_grad() 
    loss.backward()
    optimizer.step()
    # Printing stepwise progress of training
    if(i+1)%100==0:
      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
        .format(epoch+1, num_epochs, i+1, total_step, loss.item()))

"""##Densenet121"""

# Saving the features of the trained model at block 4, layer 16 i.e. last layer using a hook 

activated_features = SaveFeatures(model._modules.get('densenet121').features.denseblock4.denselayer16)
#while prediction the hook saved the weights
prediction = model(images)
pred_probabilities = F.softmax(prediction).data.squeeze()
activated_features.remove() # removing the hook from the network
# Getting the weights from the activation layer and flattening
weight_softmax_params = list(model._modules.get('densenet121').classifier[0].parameters())
weight_softmax = np.squeeze(weight_softmax_params[0].cpu().data.numpy()) # need to convert the variable to a cpu tensor, incase cuda tensor is being used.
class_idx = topk(pred_probabilities,1)[1].int() # Predicting what class each batch belongs too. 0 or 1
overlay=getCAM(activated_features.features, weight_softmax,class_idx) # clipping the weights and overlaying over the image. 
#To get a focus on what part of the image is weighed the most leading to the output
imshow(overlay[0], alpha=0.5, cmap='jet') #cmap is the color map type for better, vibrant visibility. Alpha is the opacity. Since we are overlaying over the actual image, its 0.5

imshow(overlay[0], alpha=0.5, cmap='jet')

#Resizing the tensor back to image dimensions
display_transform = transforms.Compose([
   transforms.Resize((224,224))])

#Normalizing the weights back to pixel value range i.e. 0, 255
normalize = transforms.Normalize(
   mean=[0.485, 0.456, 0.406],
   std=[0.229, 0.224, 0.225]
)
#Compiling the resize and normalization as a single processing unit.
preprocess = transforms.Compose([
   transforms.Resize((224,224)),
   transforms.ToTensor(),
   normalize
])

import numpy as np
img = images[0].cpu().numpy()[0]
#convert image back to Height,Width,Channels
#img = np.transpose(img, (1,2,0))
print(img.shape)
# printing the actual chest xray input image
imshow(img,cmap='gray')



#overlaying the activation mappings over the chest xray with alpha 0.5
imshow(img)
imshow(skimage.transform.resize(overlay[0], images.shape[2:4]), alpha=0.5, cmap='jet');